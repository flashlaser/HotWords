# coding=utf-8

import sys
import pandas as pd
import re
import jieba
import jieba.analyse

reload(sys)
sys.setdefaultencoding('utf-8')


## å¤„ç†ç‰¹æ®Šç¬¦å·
def filter_symbol(context):
    # httpæ­£åˆ™è¡¨è¾¾å¼è§„åˆ™
    re_http = re.compile(r'[a-zA-z]+://[^\s]*')
    # ä¸­è‹±æ–‡æ ‡ç‚¹ç¬¦å·æ­£åˆ™è¡¨è¾¾å¼
    re_punc = re.compile('[\s+\.\!\/_,$%^*(+\"\']+|[+â€”â€”ï¼ï¼Œã€‚ï¼Ÿã€~@#ï¿¥%â€¦â€¦&*ğŸ™„â€œâ€ã€Šã€‹ã€ã€‘ï¼šï¼ˆï¼‰]+'.decode('utf8'))

    context = context.decode('utf-8')
    context = context.strip().strip('\n')
    context = re_http.sub('', context)
    context = re_punc.sub('', context)

    return context

def keywords_extract_tf_idf(sentence):
    key_words = jieba.analyse.extract_tags(sentence, topK=15)
    words = ''.join(key_words)
    return words


if __name__=='__main__':
    sentence='#æ™“è¯´2017#èŠ‚ç›®ç¥é¢„æµ‹ï¼é«˜æ™“æ¾æŠ¼ä¸­é«˜è€ƒé¢˜ï¼Œä»é¢„æµ‹å¥¥æ–¯å¡åˆ°é¢„æµ‹#é«˜è€ƒä½œæ–‡#ï¼Œæ±Ÿè‹é«˜è€ƒè§è¯æ–°ä¸€ä»£é¢„æµ‹å¸è¯ç”Ÿï¼è¯´åˆ°å¤ä»Šä¸­å¤–æœªæ¥å‡ºè¡Œï¼Œæˆ‘åªæœ@é«˜æ™“æ¾ ï¼Œåˆ°åº•çŸ®å¤§ç´§å’‹è¯´çš„ï¼Ÿä¸åºŸè¯çœ‹è§†é¢‘[ç¬‘è€Œä¸è¯­]http://t.cn/Ra1nDIH '
    sentence=filter_symbol(sentence)
    print keywords_extract_tf_idf(sentence)

    sentence = 'é«˜æ™“æ¾æŠ¼ä¸­é«˜è€ƒé¢˜ï¼Œå°±æ˜¯ä¸çŸ¥é“è¿™ä¸€å¹´å‹äº†å¤šå°‘ä¸ªè€ƒé¢˜ã€‚å¥³å­é¢è¯•è‡ªç§°æœ‰é¢œå€¼æœ‰æ°”è´¨ï¼Œå“ï¼Œç‹—ç”Ÿå¦‚æˆï¼Œå…¨é æ¼”æŠ€ï¼Œæˆ‘å¯èƒ½é‡åˆ°äº†ä¸€åªå‡ç‹—[æ‘Šæ‰‹]#åˆ†äº«å—äº¬# http://t.cn/RMFrrlN â€‹'
    sentence = filter_symbol(sentence)
    print keywords_extract_tf_idf(sentence)