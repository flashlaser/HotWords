# coding=utf-8

import sys
import jieba
import re

reload(sys)
sys.setdefaultencoding('utf-8')


## å»é™¤æ ‡ç‚¹ç¬¦å·ä»¥åŠç‰¹æ®Šå­—ç¬¦
def filter_symbol(context):
    # httpæ­£åˆ™è¡¨è¾¾å¼è§„åˆ™
    # re_http = re.compile(r'[a-zA-z]+://[^\s]*'.decode('utf-8'))
    # re_http = re.compile(r'(?i)\b((https?|ftp|file)://|(www|ftp)\.)[-A-Z0-9+&@#/%?=~_|$!:,.;]*[A-Z0-9+&@#/%=~_|$]'.decode('utf-8'))
    re_http = re.compile(r'(?i)((http|https)[:ï¼š]?//|(www)\.)[-A-Z0-9+&@#/%?=~_|$!:,.;]*[A-Z0-9+&@#/%=~_|$]'.decode('utf-8'))
    # ä¸­è‹±æ–‡æ ‡ç‚¹ç¬¦å·æ­£åˆ™è¡¨è¾¾å¼
    re_punc = re.compile(r'[\s+\.\!\/_,$%^*(+\"\']+|[+â€”â€”ï¼ï¼Œã€‚ï¼Ÿã€~@#ï¿¥%â€¦â€¦&*ğŸ™„â€œâ€ã€Šã€‹ã€ã€‘ï¼šï¼ˆï¼‰]+'.decode('utf8'))

    context = context.decode('utf-8')
    context = context.strip().strip('\n')
    context = re_http.sub('', context)
    context = re_punc.sub('', context)
    return context


## æå–æ–‡æœ¬ä¸­çš„æ±‰å­—
def get_zh(context):
    context = context.decode('utf-8')
    context = context.strip().strip('\n')
    # æ±‰å­—æ­£åˆ™è¡¨è¾¾å¼
    re_zh = re.compile(u"([\u4e00-\u9fff]+)")
    context_list = re_zh.findall(context)
    context = ' '.join(context_list)
    return context


## è·å–åœç”¨è¯è¡¨
def get_stopwords():
    in_path='/home/littlebei/program/python/pycharm/HotWords/data/lda/stop_words_1893.txt'
    stopwords=[]
    for line in open(in_path, 'r').readlines():
        stopword=line.strip().strip('\n')
        stopwords.append(stopword)
    return stopwords


## åˆ†è¯
def seg_zh(in_path, seg_symbol, out_path):
    # åŠ è½½åœç”¨è¯
    stopwords=get_stopwords()

    out_file=open(out_path, 'w')
    for line in open(in_path, 'r').readlines():
        sentence=line.strip().strip('\n')
        sentence_filter=filter_symbol(sentence)
        seg_list=jieba.cut(sentence_filter, cut_all=False)
        seg_words=[]
        for word in list(seg_list):
            if word in stopwords:
                continue
            else:
                seg_words.append(word)
        result=seg_symbol.join(seg_words)
        out_file.write(result+'\n')
    out_file.close()

if __name__ == '__main__':
    # in_path='/home/littlebei/program/python/pycharm/HotWords/data/lda/test'
    # out_path='/home/littlebei/program/python/pycharm/HotWords/data/lda/result'
    # seg_zh(in_path, ' ', out_path)

    str = 'ä¸€è¾†æ²§å·ç‰Œç…§ï¼ˆå†€J-6W5Whttp://t.cn/RKPKTncå¥³å­å¹¸è¿åœ°å€’æŒ‚åœ¨ç”µç¼†çº¿ä¸Šï¼ŒåŒè…¿è¢«ç”µç¼†çº¿çš„ç©ºéš™ç¼ ç»•ç€ã€‚æœ€ç»ˆï¼Œæ¶ˆé˜²é˜Ÿå‘˜å°†å…¶æ•‘ä¸‹ã€‚  http://t.cn/Rokv2OI'
    # sentence = get_zh(str)
    # seg_list = jieba.cut(sentence, cut_all=False)
    # words = ' '.join(seg_list)
    # print(words)
    print filter_symbol(str)